{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2337b4db",
   "metadata": {},
   "source": [
    "## Problem 1: RAG Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc6aeb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Necessary Libraries\n",
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "import sqlite3\n",
    "import operator\n",
    "import pandas as pd\n",
    "\n",
    "from typing import TypedDict, Annotated, List\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, ToolMessage\n",
    "from langchain_ollama.chat_models import ChatOllama\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.prebuilt import ToolNode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db71f82",
   "metadata": {},
   "source": [
    "Defining Necessary variables and links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "303aea02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "DATA_DIR = \"Data\"\n",
    "DATA_FILE = os.path.join(DATA_DIR, \"HR_Policy.txt\")\n",
    "VECTORSTORE_DIR = \"hr_policy_vectorstore\"\n",
    "EMBEDDING_MODEL = \"all-MiniLM-L6-v2\"\n",
    "CHUNK_SIZE = 1000\n",
    "CHUNK_OVERLAP = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2965c4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_chunk_documents():\n",
    "    \"\"\"\n",
    "    Loads the HR policy data from the TXT file and splits it into smaller chunks.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Step 1: Loading and Chunking Documents ---\")\n",
    "    # UPDATED: Check for the .txt file.\n",
    "    if not os.path.exists(DATA_FILE):\n",
    "        print(f\"Error: {DATA_FILE} not found. Please ensure the dataset is downloaded.\")\n",
    "        return None\n",
    "\n",
    "    # Reading the text file\n",
    "    with open(DATA_FILE, 'r', encoding='utf-8') as f:\n",
    "        full_text = f.read()\n",
    "    \n",
    "    # The text splitter works on a list of documents. We treat the whole file as one document.\n",
    "    documents = [full_text]\n",
    "    \n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=CHUNK_SIZE,\n",
    "        chunk_overlap=CHUNK_OVERLAP\n",
    "    )\n",
    "    \n",
    "    chunks = text_splitter.create_documents(documents)\n",
    "    print(f\"Created {len(chunks)} document chunks from the text file.\")\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68165aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_store_embeddings(chunks):\n",
    "    \"\"\"\n",
    "    Creates embeddings for the document chunks and stores them in a Chroma vector store.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Step 2: Creating and Storing Embeddings ---\")\n",
    "    if not chunks:\n",
    "        print(\"No chunks to process. Aborting.\")\n",
    "        return\n",
    "\n",
    "    # Initialize the embedding model from HuggingFace\n",
    "    print(f\"Loading embedding model: '{EMBEDDING_MODEL}'...\")\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL)\n",
    "\n",
    "    # Create the Chroma vector store\n",
    "    # This will process all chunks and store their vector representations.\n",
    "    # It will be persisted to disk in the VECTORSTORE_DIR.\n",
    "    print(f\"Creating vector store in '{VECTORSTORE_DIR}'...\")\n",
    "    Chroma.from_documents(\n",
    "        chunks,\n",
    "        embeddings,\n",
    "        persist_directory=VECTORSTORE_DIR\n",
    "    )\n",
    "    print(\"Vector store created and persisted successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d026f0b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Step 1: Loading and Chunking Documents ---\n",
      "Created 25 document chunks from the text file.\n",
      "\n",
      "--- Step 2: Creating and Storing Embeddings ---\n",
      "Loading embedding model: 'all-MiniLM-L6-v2'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35873/200756242.py:12: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL)\n",
      "/home/sushobhon/agentic-ai-workshop/agent_env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating vector store in 'hr_policy_vectorstore'...\n",
      "Vector store created and persisted successfully.\n",
      "\n",
      "--- Data Ingestion Complete ---\n",
      "Vector store is ready in the 'hr_policy_vectorstore' directory.\n"
     ]
    }
   ],
   "source": [
    "# Manually download the dataset first as per the instructions in the function.\n",
    "doc_chunks = load_and_chunk_documents()\n",
    "if doc_chunks:\n",
    "    create_and_store_embeddings(doc_chunks)\n",
    "print(\"\\n--- Data Ingestion Complete ---\")\n",
    "print(f\"Vector store is ready in the '{VECTORSTORE_DIR}' directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75c817d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "VECTORSTORE_DIR = \"hr_policy_vectorstore\"\n",
    "EMBEDDING_MODEL = \"all-MiniLM-L6-v2\"\n",
    "OLLAMA_MODEL = \"mistral:latest\" # Make sure this model is pulled in Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5860e51c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings and vector store for RAG tool...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35873/1493662442.py:5: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vectorstore = Chroma(persist_directory=VECTORSTORE_DIR, embedding_function=embeddings)\n"
     ]
    }
   ],
   "source": [
    "# --- 1. RAG Tool Definition ---\n",
    "# Initialize embeddings and vector store once to be used by the tool\n",
    "print(\"Loading embeddings and vector store for RAG tool...\")\n",
    "embeddings = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL)\n",
    "vectorstore = Chroma(persist_directory=VECTORSTORE_DIR, embedding_function=embeddings)\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3}) # Retrieve top 3 results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bec82954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining retrive data function\n",
    "@tool\n",
    "def retrieve_hr_policy_info(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Searches the HR policy vector database to find relevant information\n",
    "    for a given user query. Use this to answer questions about HR policies,\n",
    "    such as leave, benefits, code of conduct, etc.\n",
    "    \"\"\"\n",
    "    print(f\"\\t--- Executing RAG Tool for query: '{query}' ---\")\n",
    "    results = retriever.invoke(query)\n",
    "    \n",
    "    if not results:\n",
    "        return \"No relevant information found in the HR policy documents.\"\n",
    "        \n",
    "    # Format the results into a single string to be passed to the LLM\n",
    "    context = \"\\n\\n---\\n\\n\".join([doc.page_content for doc in results])\n",
    "    print(\"\\t--- RAG Tool Finished ---\")\n",
    "    return f\"Retrieved context: \\n{context}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "798aa893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Agent State and Graph Definition ---\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[List[BaseMessage], operator.add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b419422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Graph Nodes and Conditional Logic ---\n",
    "\n",
    "def should_continue(state: AgentState) -> str:\n",
    "    \"\"\"\n",
    "    Decides the next step. If the LLM made a tool call, route to the 'tools' node.\n",
    "    Otherwise, end the process.\n",
    "    \"\"\"\n",
    "    last_message = state['messages'][-1]\n",
    "    if last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    return END\n",
    "\n",
    "def call_model(state: AgentState):\n",
    "    \"\"\"\n",
    "    Calls the Ollama LLM. It will either respond directly or decide to use a tool.\n",
    "    \"\"\"\n",
    "    messages = state['messages']\n",
    "    # The final response generation should not use the tool-calling model\n",
    "    # to avoid loops. We'll decide which model to use based on the flow.\n",
    "    # If the last message was a tool result, we use the base model to synthesize an answer.\n",
    "    if isinstance(messages[-1], ToolMessage):\n",
    "        print(\"\\t--- Synthesizing final answer from tool output ---\")\n",
    "        response = model.invoke(messages)\n",
    "    else:\n",
    "        # This is the first call, where the model can decide to use a tool.\n",
    "        print(\"\\t--- Agent is deciding next step (respond or use tool) ---\")\n",
    "        response = model_with_tools.invoke(messages)\n",
    "        \n",
    "    return {\"messages\": [response]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af9e0001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- HR Policy RAG Agent Initializing ---\n"
     ]
    }
   ],
   "source": [
    "print(\"--- HR Policy RAG Agent Initializing ---\")\n",
    "    \n",
    "# Check if the vector store exists\n",
    "if not os.path.exists(VECTORSTORE_DIR):\n",
    "    print(f\"Error: Vector store not found at '{VECTORSTORE_DIR}'\")\n",
    "    print(\"Please Create Vector store first.\")\n",
    "    exit()\n",
    "\n",
    "# Define the tool(s) for the agent\n",
    "tools = [retrieve_hr_policy_info]\n",
    "\n",
    "# Initialize the Ollama model\n",
    "model = ChatOllama(model=OLLAMA_MODEL)\n",
    "\n",
    "# Bind the tool to the model\n",
    "model_with_tools = model.bind_tools(tools)\n",
    "\n",
    "# Define the LangGraph workflow\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "workflow.add_node(\"agent\", call_model)\n",
    "workflow.add_node(\"tools\", ToolNode(tools))\n",
    "\n",
    "workflow.set_entry_point(\"agent\")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"tools\": \"tools\",\n",
    "        END: END\n",
    "    }\n",
    ")\n",
    "workflow.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "# Compile the graph\n",
    "app = workflow.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff6ea460",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "display(Image(app.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f8746e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting HR Policy Assistant ---\n",
      "Type 'exit' to end the conversation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Your question:  What was my previous question?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- #### ----\n",
      "\t--- Agent is deciding next step (respond or use tool) ---\n",
      "\n",
      "\t--- Output from node 'agent':\n",
      "\tTool Call: [{'name': 'retrieve_hr_policy_info', 'args': {'query': 'HR policy for taking time off during the holiday season'}, 'id': 'a1daaa7a-e2d6-4048-a16c-3d29f79148df', 'type': 'tool_call'}]\n",
      "\n",
      "\n",
      "\t--- Executing RAG Tool for query: 'HR policy for taking time off during the holiday season' ---\n",
      "\t--- RAG Tool Finished ---\n",
      "\n",
      "\t--- Output from node 'tools':\n",
      "\n",
      "\n",
      "\t--- Synthesizing final answer from tool output ---\n",
      "\n",
      "\t--- Output from node 'agent':\n",
      "\n",
      "\n",
      "\t--- Agent is deciding next step (respond or use tool) ---\n",
      "\t--- Executing RAG Tool for query: 'company's policy on taking time off during a pandemic' ---\n",
      "\t--- RAG Tool Finished ---\n",
      "\t--- Synthesizing final answer from tool output ---\n",
      "---- #### ----\n",
      "Final Answer:  The previous question was \"What steps should I take if I need to take a leave of absence from work, such as for medical reasons or personal circumstances?\" and the corresponding answer provided was:\n",
      "\n",
      "\"If you need to take a leave of absence, you should notify your supervisor and HR department as soon as possible. They will guide you through the process and provide the necessary documentation, such as medical certification or family leave forms, depending on the type of leave you require. The specific policies and procedures for leaves of absence, including eligibility, duration, and benefits during the leave, will be communicated to you.\"\n",
      "\n",
      "This answer suggests that employees who need to take a leave of absence should first inform their supervisor and HR department about their situation. They will then be guided through the necessary process, which may include providing documentation such as medical certification or family leave forms. The policies and procedures for leaves of absence, including eligibility, duration, and benefits during the leave, will be communicated to the employee.\n",
      "---- #### ----\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Your question:  What is the process for approval to request time off?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- #### ----\n",
      "\t--- Agent is deciding next step (respond or use tool) ---\n",
      "\n",
      "\t--- Output from node 'agent':\n",
      "\tTool Call: [{'name': 'retrieve_hr_policy_info', 'args': {'query': 'What is the process for approval to request time off?'}, 'id': 'e6e21e01-98b1-4f83-8c99-2663c18ef81d', 'type': 'tool_call'}]\n",
      "\n",
      "\n",
      "\t--- Executing RAG Tool for query: 'What is the process for approval to request time off?' ---\n",
      "\t--- RAG Tool Finished ---\n",
      "\n",
      "\t--- Output from node 'tools':\n",
      "\n",
      "\n",
      "\t--- Synthesizing final answer from tool output ---\n",
      "\n",
      "\t--- Output from node 'agent':\n",
      "\n",
      "\n",
      "\t--- Agent is deciding next step (respond or use tool) ---\n",
      "\t--- Executing RAG Tool for query: 'What is the process for approval to request time off?' ---\n",
      "\t--- RAG Tool Finished ---\n",
      "\t--- Synthesizing final answer from tool output ---\n",
      "---- #### ----\n",
      "Final Answer:  Based on the provided context, here's a summary of the process for requesting time off:\n",
      "\n",
      "1. Employees should follow the designated process outlined in their employee handbook.\n",
      "2. Typically, this involves submitting a request through an online system or directly to their immediate supervisor or the HR department.\n",
      "3. The request should include the desired dates and the reason for the time off.\n",
      "4. Approval is subject to manager discretion and business needs.\n",
      "5. Employees will receive a response confirming or denying their request.\n",
      "---- #### ----\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Your question:  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- #### ----\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Starting HR Policy Assistant ---\")\n",
    "print(\"Type 'exit' to end the conversation.\")\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"\\nYour question: \")\n",
    "    print(\"---- #### ----\")   \n",
    "    if user_input.lower() == 'exit':\n",
    "        break\n",
    "    \n",
    "    inputs = {\"messages\": [HumanMessage(content=user_input)]}\n",
    "    \n",
    "    # Stream the intermediate steps to see the agent's reasoning\n",
    "    for output in app.stream(inputs):\n",
    "        for key, value in output.items():\n",
    "            print(f\"\\n\\t--- Output from node '{key}':\")\n",
    "            # Print the message content for clarity\n",
    "            if 'messages' in value:\n",
    "                for msg in value['messages']:\n",
    "                    if hasattr(msg, \"tool_calls\") and msg.tool_calls:\n",
    "                        print(f\"\\tTool Call: {msg.tool_calls}\")\n",
    "            else:\n",
    "                print(value)\n",
    "        print(\"\\n\")\n",
    "    \n",
    "    # The final answer is the last message from the 'agent' node\n",
    "    final_response = app.invoke(inputs)\n",
    "    print(\"---- #### ----\")\n",
    "    print(\"Final Answer:\", final_response['messages'][-1].content)\n",
    "    print(\"---- #### ----\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00c3ac9",
   "metadata": {},
   "source": [
    "## Problem 2: Python Coding Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "82fff654-7e24-496b-b0be-be7e93152ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries\n",
    "import re, os\n",
    "import operator\n",
    "import subprocess\n",
    "import sys\n",
    "import sqlite3\n",
    "from typing import TypedDict, Annotated, List\n",
    "\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, ToolMessage, AIMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_ollama.chat_models import ChatOllama\n",
    "from langgraph.graph import StateGraph, END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6ba4df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "OLLAMA_MODEL = \"mistral:latest\" # Make sure this model is pulled in Ollama\n",
    "DB_FILE = \"code_agent_memory.db\" # New database file for this agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7373493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Memory Management (SQLite) ---\n",
    "\n",
    "def setup_database():\n",
    "    \"\"\"Initializes the SQLite database and creates the memory table if it doesn't exist.\"\"\"\n",
    "    conn = sqlite3.connect(DB_FILE)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS code_memory (\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        role TEXT NOT NULL,\n",
    "        content TEXT NOT NULL\n",
    "    )\n",
    "    \"\"\")\n",
    "    conn.commit()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c7310ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_message(message: BaseMessage):\n",
    "    \"\"\"Saves a single message (Human or AI) to the database.\"\"\"\n",
    "    conn = sqlite3.connect(DB_FILE)\n",
    "    cursor = conn.cursor()\n",
    "    role = 'unknown'\n",
    "    if isinstance(message, HumanMessage):\n",
    "        role = 'human'\n",
    "    elif isinstance(message, AIMessage):\n",
    "        role = 'ai'\n",
    "    \n",
    "    if role != 'unknown':\n",
    "        cursor.execute(\"INSERT INTO code_memory (role, content) VALUES (?, ?)\", (role, message.content))\n",
    "        conn.commit()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e46530d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_messages() -> List[BaseMessage]:\n",
    "    \"\"\"Loads all past messages from the database to reconstruct the conversation history.\"\"\"\n",
    "    if not os.path.exists(DB_FILE):\n",
    "        return []\n",
    "    conn = sqlite3.connect(DB_FILE)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"SELECT role, content FROM code_memory ORDER BY id ASC\")\n",
    "    rows = cursor.fetchall()\n",
    "    conn.close()\n",
    "    \n",
    "    messages = []\n",
    "    for role, content in rows:\n",
    "        if role == 'human':\n",
    "            messages.append(HumanMessage(content=content))\n",
    "        elif role == 'ai':\n",
    "            messages.append(AIMessage(content=content))\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbd39461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Tool Definition for Code Execution ---\n",
    "# This tool simulates our \"Executor Agent\". It takes Python code as input,\n",
    "# executes it in a separate process, and returns the output or any errors.\n",
    "\n",
    "def execute_python_code(code: str) -> str:\n",
    "    \"\"\"\n",
    "    Executes a given string of Python code in a separate process.\n",
    "    It captures and returns the standard output and standard error.\n",
    "    \"\"\"\n",
    "    print(\"\\t---EXECUTOR AGENT: Attempting to execute code.---\")\n",
    "    print(\"\\tCODE:\\n--- ### ---\")\n",
    "    print(code)\n",
    "    print(\"--- ### ---\")\n",
    "    try:\n",
    "        # Using subprocess to safely execute the code in a new python interpreter\n",
    "        result = subprocess.run(\n",
    "            [sys.executable, \"-c\", code],\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            check=True, # This will raise CalledProcessError if the command returns a non-zero exit code\n",
    "            timeout=30 # Add a timeout for safety\n",
    "        )\n",
    "        output = result.stdout\n",
    "        print(f\"\\t---EXECUTOR AGENT: Execution successful.---\\n--- ### ---\")\n",
    "        print(f\"OUTPUT:\\n{output}\")\n",
    "        print(\"--- ### ---\")\n",
    "        return f\"Execution successful. Output:\\n{output}\"\n",
    "\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        # This catches errors from within the executed script (e.g., Python syntax errors)\n",
    "        error_message = f\"Execution failed with error:\\n{e.stderr}\"\n",
    "        print(f\"\\t---EXECUTOR AGENT: Execution failed.---\\n--- ### ---\")\n",
    "        print(error_message)\n",
    "        print(\"--- ### ---\")\n",
    "        return error_message\n",
    "    except subprocess.TimeoutExpired:\n",
    "        error_message = \"Execution failed: The code took too long to run (timeout).\"\n",
    "        print(f\"\\t---EXECUTOR AGENT: {error_message} ---\")\n",
    "        return error_message\n",
    "    except Exception as e:\n",
    "        # Catch other potential errors during subprocess setup\n",
    "        error_message = f\"An unexpected error occurred during execution: {e}\"\n",
    "        print(f\"\\t---EXECUTOR AGENT: {error_message} ---\")\n",
    "        return error_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25bf805b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Agent State Definition ---\n",
    "# This state will be passed between the nodes of our graph.\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    task: str\n",
    "    code: str\n",
    "    result: str\n",
    "    messages: Annotated[List[BaseMessage], operator.add]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dad24521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. Agent and Node Definitions ---\n",
    "\n",
    "# This is our \"Generator Agent\". It's an LLM prompted to be a Python programmer.\n",
    "code_gen_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"You are a senior Python programmer. Your task is to write a complete, single Python script to solve the user's request.\n",
    "                The script must be executable and should print the final answer(s) to the standard output.\n",
    "                Do not use any imports that are not part of the standard Python library.\n",
    "                If you are given an error message, you must analyze the previous code and the error, then generate a new, corrected version of the script.\n",
    "                Your response must ONLY contain the Python code inside a single block. DO NOT add any preamble or any kind of text.\n",
    "            \"\"\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "llm = ChatOllama(model=OLLAMA_MODEL, temperature=0)\n",
    "code_generator_agent = code_gen_prompt | llm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3cd18379",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_python_code(text):\n",
    "    \"\"\"\n",
    "    Extracts Python code blocks from text using regex.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text containing code blocks.\n",
    "\n",
    "    Returns:\n",
    "        list of str: A list of extracted Python code blocks.\n",
    "    \"\"\"\n",
    "    # Regular expression pattern to match ```python ... ```\n",
    "    pattern = r\"```python\\s*(.*?)\\s*```\"\n",
    "    # Use re.DOTALL to allow newlines inside code blocks\n",
    "    code_blocks = re.findall(pattern, text, re.DOTALL)\n",
    "    return code_blocks[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "208e65e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_node(state: AgentState):\n",
    "    \"\"\"\n",
    "    This node invokes the code generator agent to write or correct the Python code.\n",
    "    \"\"\"\n",
    "    print(\"\\t---GENERATOR AGENT: Thinking...\")\n",
    "    # The message history provides context, including the original task and any previous errors.\n",
    "    response = code_generator_agent.invoke({\"messages\": state[\"messages\"]})\n",
    "    save_message(response) # Save the AI's response to memory\n",
    "    \n",
    "    # Extract the code from the AIMessage, cleaning up markdown fences\n",
    "    code = extract_python_code(response.content)\n",
    "    \n",
    "    print(\"\\t---GENERATOR AGENT: Generated new code.---\")\n",
    "    return {\"code\": code.strip()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8961a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def executor_node(state: AgentState):\n",
    "    \"\"\"\n",
    "    This node calls our code execution tool to run the generated code.\n",
    "    \"\"\"\n",
    "    result = execute_python_code(state[\"code\"])\n",
    "    return {\"result\": result}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e361bb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conditional_router(state: AgentState):\n",
    "    \"\"\"\n",
    "    This is the core logic. It checks the execution result and decides where to go next.\n",
    "    \"\"\"\n",
    "    print(\"---ROUTER: Analyzing execution results...---\")\n",
    "    if \"Execution failed\" in state[\"result\"]:\n",
    "        print(\"---ROUTER: Execution failed. Routing back to Generator Agent for correction.---\")\n",
    "        # Add a message to the history to inform the generator of the error\n",
    "        error_content = f\"\"\"The previous code you wrote failed.\n",
    "                \n",
    "                            ### PREVIOUS CODE:\n",
    "                            {state['code']}\n",
    "\n",
    "                            ### EXECUTION ERROR:\n",
    "                            {state['result']}\n",
    "\n",
    "                            Please analyze the error and provide a corrected version of the full script.\"\"\"\n",
    "        error_message = HumanMessage(content=error_content)\n",
    "        save_message(error_message) # Save the corrective prompt to memory\n",
    "        return {\"messages\": [error_message]}\n",
    "    else:\n",
    "        print(\"---ROUTER: Execution successful. Ending workflow.---\")\n",
    "        return END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f3c2e192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. Graph Definition and Execution ---\n",
    "\n",
    "# Define the graph\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# Add the nodes\n",
    "workflow.add_node(\"generator\", generator_node)\n",
    "workflow.add_node(\"executor\", executor_node)\n",
    "\n",
    "# Set the entry point\n",
    "workflow.set_entry_point(\"generator\")\n",
    "\n",
    "# Add the edges\n",
    "workflow.add_edge(\"generator\", \"executor\")\n",
    "# The conditional edge decides the next step after execution\n",
    "workflow.add_conditional_edges(\n",
    "    \"executor\",\n",
    "    conditional_router,\n",
    "    {\n",
    "        \"generator\": \"generator\", # If failed, go back to the generator\n",
    "        END: END                  # If successful, end\n",
    "    },\n",
    ")\n",
    "\n",
    "# Compile the graph into a runnable app\n",
    "app = workflow.compile()\n",
    "\n",
    "# Setup the database for persistent memory\n",
    "setup_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ccedbd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHMAAAFNCAIAAAC8JsfYAAAAAXNSR0IArs4c6QAAIABJREFUeJztnXlcE0ffwCd3SEISSIBwX8qNoCAor9Ui3hfS4n3WWmu1tlqpj9Z629Z61qO2xdb7qVe1XtVqvRVFBUUFQW5B7jP3nX3/CA+lGkg27EBC9/vxD5KdWX58P+NvZ3dmZwgIggAcCBA7O4AuC24WFrhZWOBmYYGbhQVuFhZkDM8ll2jqK9UysUYm0mo1iEZjBf05mg2RQiMybElMNsnBjY7hmTEwK6xXF2RICp9JlXKtDYvEsCUz2CQWhwysQCzQapDaMrlMrKUxiCU5Mp8Qlnco0zuY2f4zE9pzp6BS6O6erxU3aOydqD6hTGdvm/YH1InIJdrCTElFoaKyWBEzmucTymrP2cw3++R2Y+ofdTGj+KH9OO2JwAJpqFbdPVdHIIAhU53IVDMvRWaavXy4kiegRgyyN++3WgXVpYqTO8sS5rsKPM3Jv+aYPfNDWUBvtn+krRm/z+o4sa108FQnrgMVbUXUZo9tKY0YxO0W9q/QqufEd6VRQ+09A9Fd1tAlkStHqnr04/yrtAIAxi10v3q0WirUoKqFwmzmPSHXgRIYzUYfm9Uz5T8eV45UoaqCwuyN4zWRXfqS1QY0BsnRnZ72V73pVUw1e/dcbd9RPHMD6wr0Hcm7/2e9TmvqZckkswqpprZcFRFn177YrJ63Ex3SrzaYWNgks0WZMgab1L6ougJufozs+yITC5tktjBT6hOCwa00KpYuXXrmzBm0tQoKCkaNGgUnIsDhUchUYl2F0pTCxs0iOkTSoMbkIQUqnj9/3mG1TMc/glWaKzelpPE7BWGd+szusukrvDCK7XVSUlIOHjyYlZXF5/PDwsIWLFjA5/MjIyP1R1ks1o0bNyQSyeHDh+/du1dQUMDn8wcMGPDRRx/R6XQAQFxc3OzZs69du/b48eNp06YdOnRIX3HRokVTpkzBPNrs+6KyQvmgSU7GiyLGKC+Unfiu1Ggx88jOzo6IiNizZ09FRUVKSsrEiRPnz5+PIIhCoYiIiDh9+rS+2J49e6Kjo//666+HDx9eu3Zt+PDh27dv1x8aOnTouHHjNm3alJqaqlart2/fPnLkSEjRIghS/Fxy5scyU0oafz4rFWqZHFiXr4yMDDqdPmvWLCKRKBAIgoKC8vPz3yw2derUuLg4b29v/ccnT57cvXv3k08+AQAQCAQOh5OUlAQpwtdgcsgm3owZN4sgCJUOa1AnPDxcoVAsXLgwOjq6f//+7u7uzXmgJRQK5d69e6tWrcrNzdVoNAAAe/u/71mCgoIghfcmJBIgUwmmlDSujGFLFtWiu2U2nYCAgB07djg4OOzcuTMhIWHevHlPnjx5s9jOnTuTk5MTEhJOnz6dlpb23nvvtTxKpaJ+EGU2EqGWYtoTWxPMsklSESyzAICYmJgVK1acO3du9erVQqFw4cKF+lbZDIIgJ0+enDBhQkJCgkAgAACIxWJ48bSNTKQ1sWtv3CyTS2bZYTkQ2ZL09PS7d+8CABwcHEaNGrV48WKxWFxRUdGyjFqtlsvljo6O+o8qlerWrVuQ4jGKSqHju5j0X8S4WSqVCBBQmivDIrDXefLkyZIlS06dOtXQ0JCZmXn06FEHBwdnZ2cajebo6JiampqWlkYkEr28vM6ePfvq1avGxsa1a9eGh4eLRCKpVPrmCT08PGpra2/cuPHy5UsYAeekiVx8GKaUNClleAczi7IM/BntZ+rUqQkJCZs3bx48ePCcOXOYTGZycjKZTAYAzJo16+HDh4sXL5bL5V9//TWdTk9MTBw7dmxUVNTHH39Mp9MHDRpUXl7+2gn79esXHh6elJR06dIlzKOVS7TCWrXAy6TBG5PGFIS1qjtnake+74JFeFZM3mNxTZkyZhTflMImtVkOn0qzIWU/MPVhRFflzpnaHv24JhY29dIUM5p3ZGNpYJThAQWVSjVkyJDWDlEoFALBQB/Qx8dn7969JgaAlv379+/fv9/gIRaLJZFIDB6KjIzcvHmzwUNPbzf6hLJYXFONoRhhfHi5nskmBfUxPLugtZ6QUqmk0WiGfzeBwGK1a7ZEGyiVSpVKZfCQSqVqrQtMIpEYDMMXqDM/lA2f5UylmXrThG7s9uTOV31H8Fx8rXsujBmc2vkqegTPFc0fju629d0Fbud/rlDIIN44WCCXDlV2C2eh0mrOfAOtFjmwpnj0hy4Orob/j3cxLh+u9Otl6xWE+vG0mbOPjm4qiRxi17UnHqhVut93lYXEcIL6mDMRwPwZc3dO11QWK/uORpd9rIV7f9SV5MjeHufg5GHmpNp2zfKsKJbfO1dn70wVeNG9g5k0G6sfhawsVrzKl92/WB89zD5ikJ3BzqKJtMusnpIc2Ys0cVGW1LWbDYtDZnJITDaZwSZpte08cUdAAIioXqN/mJd9X8zmkbuFscL6c4kk8502nRnDdxjLCmR1FSqpUCsVaQgAKGQ6rM6s7y+Xl5f7+/tjeE4AAItDIhAJTDbZlkd262bDsMXsqR6WZqGSnp7+008/JScnd3YgpoK/WwML3CwscLOwwM3CAjcLC9wsLHCzsMDNwgI3CwvcLCxws7DAzcICNwsL3CwscLOwwM3CAjcLC9wsLHCzsMDNwgI3CwvcLCxws7CwGrNEIrHle4uWj9WY1el09fUolnHpdKzGrNWBm4UFbhYWuFlY4GZhgZuFBW4WFrhZWOBmYYGbhQVuFha4WVjgZmGBm4UFbhYWlv6m3YQJE2QyGZFIlMvlEomEx+MRiUSpVHrlypXODs0Ilt5mY2NjKyoqysrK6uvrVSqV/mdbWyt4+9/SzU6cONHT0/O1L4cPH95J4aDA0s1yudzBgwe3fBve3d194sSJnRqUSVi6WQDApEmTXF1dmz+OGjWKzbaC3TKswCyHwxkxYoS+2bq5uY0fP76zIzIJKzALABg/frybmxuBQBg5cqRVXL5MWmNOrdTVVahkks5dYYMypN+01NTUvmFjCzOhrH1pIiQSwc6JwranGC1ppD9761RNfoaEySHbsGAtQWtdsLjkkhypnYAaPcy+7R3Z2jJ7cV+FnTM9uO+/fVOVN5FLNZcPlA2fIeC5tLpoWatm//pvFdeJFtDb1KUr/4Wc2Fo0fpF7a2tQGr6CVZUqFHIdrrVt+o5xfHCp1QlRhs3WV6jIFOvoNnQiHB61jUW6DeuTijRcfsctpW+l2NpRSCQCojOcTg2b1WmB1hr2ru50GmvUBKLhNdPw//KwwM3CAjcLC9wsLHCzsMDNwgI3CwvcLCxws7DAzcICNwsL3CwsurjZNWuXXriIegttTOjiZl+8gLsZdhtgNm7Y0FD/zYaVWc+ferh7xcePe/Wq5Pad6wf2/QYA0Gg0v+zdnXr/TnV1ZUhIeEL8+D59+gEAiooKZs2esPv7A7/+uu9Oyg0HB8fYt4fM+WABiUQCANTX1+3+YWtm1hOFQtG7d9/pU2e7u3sCAE6eOvrrkX2LFi5btXrJ2LHjF8xPKioqOHvut0ePH1ZWlnt5+owYMTZ+TCIAIDYuEgCwafO6H37cdu7MDQBASsrNAweTX5YUcTjcbt38P13wHycnAQBg1eolJBLJycn56LGDa1Zv7P/WwPYLwazNbty8tqS0eNPG3evXbb1/P+X+/RQisenkO3Zu/O3krwljJ/z633MD+setWrPk5q2r+v2BAQBbtq6Pixt2+c97y5etP37i8PUbfwEAtFrtosUfZjxJX7Twi70/H7Pj2s+bP6Os/JV+d1uZTHr27G/Llq5NiB8PAPh+95aHD+99+sl/NnyzY8SIsdt3fJt6PwUA8OeFFADA50kr9FrT0u+vXP35kCEjjx+9sGrFhqqqiu92bNBHSKFQCovyC4vyv1q3tUdoT0yEYGNWKGxMTb0zfty0oMAQHo+/+LMvKyub9p5UKpWXLp+fPGnmmNHvcticEcPj4wYOO3hoT3PdAf0HvT1gEIVCCQvr5eLsmpubDQB49iyjpKT4i2XroqNi7O15H81dyOZwT578Vb9fm0KhmDhxxqC4YW5uHgCAFSu+2bRpd6+evXuGR8aPSfT3C3zw8O6bQe7d90P/twYmvjuZw+EGB/eY99Fnqal3cl4815+zsrJ8zaqNMTH9uVxsxqqxyQYFhXkAgJCQMP1HFovVq1dUSWkxACA3N1ulUvWO7NtcODws4uKfZ4Uiof6jn19g8yEWy1YiEQMAnmVmUCiUXj17678nEAjhYRFPnj5qLhngH/z3r0eQU6eO3n+QUlratBOrs/Pf88CaKSzMG9A/rvmjv18QACAnJyvAPwgA4OnhTaebufmPQbAxKxaLAABM5t9b/7HZTZsK6k0t+PT916o01Nfpd19tThotkUjEarVanyibadmamrf70+l0S7/4VK1WfTD74/DwSFuW7Zu/CwAgkUiUSiWN9rc7/a6AMlnTjBtqK1samg02ZvURq1vse9jQ2DRczOM7AAAWf7bc1dW9ZRVHR0F9fW1rJ+Tx+DY2Nl+t39bySxLRwF5OuXk5OTlZmzftjugVpf9GIhE78B1fK6ZvjwqFvPkbqUwKAODZm7TFqhlgY1Z/1S4qLvDy8tE3kEePHjg5OQMA3Fw99Dtc9gxvaoANDfUIgjAYjDYWL/H19ZPL5Y6OAlcXN/035RVlXI6BDCgUNgIAmlUWFxcWFxd6e/m+/neSyf5+gVlZT5u/0f/s49sdg7/fENhcwVxd3Dw9vQ8cTC4rfyWRSL7b/k1zpmMwGDNnfHjw0J5nzzJUKtXNW1eTlsz7bvuGtk8Y0SsqKipm8+Z1VVWVQmHj6TMn5n407c8/z75Z0svTh0wmHzt+SCQWlZQU79y1qXdkn8qqCgAAjUZzcHBMS0t9nJGm0WgSxk64k3Lj5MkjIrHocUba7h+29urZu3s3jDdvagaz/uySpJWbt66fNj3B16f74MEjmExWdnam/tDECdN9ff1+Pbr/0aMHTCYrOKjH4sVfGj3hN199d/bcybXrlz1//szd3XPQoOHvvGNgqreTk2D5F+sPHEyOHzvQ1dV9+bJ1dfW1K1YmzXgv8cC+36ZMnrVv/48PHt498uv5IUNG1tRWHztxaNfuLU5OgsiIPh/M/hirP/9NDM/renCpXqUAYW+jWMVJKGxUKBT6jjcAYNnyhWQSed1aw7vydhkOrM7/eFs3g4cwu1NYs3bpos/m3L5zXShsPHT4l/T0+2PGJGJ1cmsEs2ywatW3mzav3fPzrpqaKk8P71UrNvSO7IPVya0RzMxy2Jz1a7dgdbYuQBd/1tWJ4GZhgZuFBW4WFrhZWOBmYYGbhQVuFha4WVjgZmFh+O6WziDptFjuZN8l0ekQgXerQ2eG2yyHT64olhs8hNNMXblSp2313S7DZt26M1Tyzn3t3gqoLpV3C2e1dtSwWRKZED3M/vLBMpiBWTf5T0Tl+dJesa1OTmjrLfyyAvmlg5XhA+y5TjR8fQM9BAJSW64U1anL86WJn7q1VbLtlSMkjZpH1xoqixVycUcnBx2CaNTq5nkFbyKTyxk2Nh0bFLB3oRGJwDOQERLDMVIUsVQOHz68ZcuW1o7u3LkzMjKyjQKdjuX2Z58/fx4UFNTa0QcPHmi12rNnz16+fLlj4zIVyzWbk5MTEBBg8FB5eblQKCQSiRKJZOfOneXl5R0enXEs1KxMJquurvby8jJ4NDs7u6amRv9zRUXF559/3rHRmYSFms3Ozm4jFaSkpCgUiuaPL168WLVqVUeFZiqWa7a1VAAAyMzMbLlSIgDg1q1bR44c6ZDQTMVCzbZ9+RKLxQQCQafT6XQ6BEEoFAqNRps0aVLHxmgEC+3/Z2dnz507t7WjIpFIIBCcP3++Y4NChyWalUgk9fX1Hh4erRVISUnR/3DhwgWRSGSZi6ZaYjZoo7/1Go6OjtevX4cfkTlYotm2k2xLevXqtXz5cvgRmYMlms3Ozg4MDDShICASiW0kjc7FEs2a3mYBAN9+++3NmzchR2QOFmdWIpE0Nja6ubX1gK4lbm5u6enpkIMyB4vrG6BqsPoNF1rej1kOFtdmTU+yeshkMovV6pBJJ2JxZtG2Wf2eCyUlJdAiMhOLM2t6Z7YZX1/f58877W371rCsfWtEIlF8fLzFdv5RYVltFm2S1aPT6SzwItYVzKrV6oEDMVjrAVssy6wZly/9W6CBgYEvX76EE5SZWFaeHT169E8//eTi4tLZgWCABbVZoVAolUrN0yqRSEQiEYSgzMeCzBYXFw8YMMC8unl5edu3b8c6onZhQWaDg4MvXLhgXt2CggI/Pz+sI2oXFvTcgEwme3l55efnd+tm+O3rNkhMtLi3py2ozQIAgoKCzLubysvL02g0ECIyH8syGxgYmJ2djbZWXV3d/Pnz9ev9WA6WZda8NlteXj5y5Eg4EZmPZfVntVpt3759Hzx40NmBYIBltVkSieTr65ubm4uqVk5OTn0b6yh1EpZl1rxUu3DhQq3W4t6qsDizwcHBWVlZppcXiUQxMTEODg4wgzIHizMbEBCQk5Njenk2m71y5UqYEZmJxZlF2z3Iy8vLz8+HGZGZWJxZAoHg7+9verP9/vvvKyoqIAdlDhZnFu1FzNPTs2dPbNbixRZLNIsqISxatAgfFTcV09vsq1evbt++DT8ic7BQsybm2bNnz6K9regwLOspRjMBAQHDhg1Tq9VCodDX1/fYsWMGi7m7u/fo0aPDozMJyzI7YMAAkUhE+B/6VywjIyNbKz969OiODRAFlpUNoqOjCQQCkUhsfnWGxWL17t3bYGGJRHLw4MGODRAFlmV2w4YNvr7/WEjazs4uNDTUYOGHDx8+ffrU4CFLwLLMEonENWvWODo2Ldqt0+lcXFx4PJ7BwnZ2djNnzuzYAFFgWWb1ndmZM2fa/O/1+jaSbHh4eEhISAeGhg6LMwsAGD9+fGxsLIIg9vb2bdxfbdu2TS633MVuUPcNJI1qBDG8kzaGfL5oZWlRrVgs9nYPEjcYGDqsrq5Ouflo9kyKWAF9YBFBEBaHTCSh+6tRjNbc+K0675FE4G1TX640K0J06BCESGj1j9EhiE6nI5MM7F2BOWQqobFW7exFDxvA9e1h6p20SWbVSl3yssK4yc58NzrNpiP+GAtEVK9Ku1TrE8oM/T9j65wAYKrZ5GWF7y70pNL/pU5bcutkpVt3ethbXKMljV/BUi/URQ3n41r19H9XUJwpk0uNJ3fjZktfyG3tKRgF1hXQapDaMpXRYsbNkqkErgPGOzxZNU5eNsI6tdFixs3WlCktaK6HBaCQ6zQq40os8U6ha4CbhQVuFha4WVjgZmGBm4UFbhYWuFlY4GZhgZuFBW4WFrhZWHRBs0VFBRMnj+rsKLqi2Re5FrGmDBSzWVlPl/zn4zHxsdNmvLP7h21SqRQAoNFops14Z+Wqv1eOXpz00ew5k/RvdRqsoufevdsTJ4+KGxz14dypF/+3tfiy5QuXLV/YXObSpfOxcZEymWzf/h+/3bimqqoyNi7yxG//1S9svf7rLxPHDxs6PObDuVNPnzmhr3Ly1NF3xw29k3IjbnDU7TvYr1yDvdlXZaVJS+YplIpdO/etW7O5sDBv0WdzNBoNmUxeumT17TvX09LvAwBu3rr69NnjL7/4ikwmt1ZFr3XFqqT3Z83f8M2Ofv1iN25ae+Xqn2389vdmzp04YbqTk+D61bRxiVMAAEu/+KS8/NW6tVuOH73Qv3/c9h3fZudkAQCoVKpMJj179rdlS9eGhoRj7gF7s1euXKSQKevWbPbw8PLy8klavCIv/8WdlBsAgODgHvFjErdt+1omk+3+Yet7M+d6efm0XWXf/h/7vzVw8KDhvSP7TJv6/oTx02QyqQlRNJF6P+XZs4zPF68IDAjmcLhTJr8XGhp+4GCy/oUIhUIxceKMQXHDuNxWN0kxG+zNZmU9CQgI5nCaRjcFAmcXF7enzx7rP8754BOlSjl33jQ+33HihOltV9HpdAWFeQEBwc0nn/vhp2NGv2t6MEVF+XQ63dv771l4ft0DX7z4OxEH+Ae3UrW9YD9/ViIR57x4Hhv3j/lYDfV1+h8YDMbY+PG/7N393sy5RCKx7SoKhUKn09Fore7BZZS6ulo6/R87sDAYDLlc1vyxjd1b2gn2Zu15/NDQ8Pdm/mOVbg67qT0KhY2/nz4W+/bgI0f3Dx48wlng0kYVGo1GJBKlUonRX6rVGX47lMlkKhT/mPsllUn5vI544RH7bODr0726ujKsR6+e4ZH6f3Zcew+Ppj0ndn2/2dPDe+WKb3x9/bZu/artKiQSyd8/6FlmRvPJ9/y86/vdWwEAVAq1ZcItLTW8pJS/X5BCocjLf9H8TXZ2ppe3r8HC2IK92cTEKTqdbtfuLQqForT05U/JO2bNnlBYlA8ASE29c/PW1cWLvwQALElamfEk/dKl821XiR+d+PDhvWPHDz3OSDtz9rcjRw/ok2ZgYEhOTlZhYT4AIC39vv5yp8fNzaOurvbOnRulpS+jomJcXNy2bv0q58Xz+vq6X/buzs7OnDBuGuZ/9Ztgnw3Ytuxffj529OiBDz+aWlJSHBAQ/HnSCr/uARKJ5NtNayZNnOHq4gYA8PDwevedSbt/3NanTz8Oh2uwCgBg6NBRIrHwwMFkqVTK4/HnfLBgxPB4AMDY+PElJcVz5k7RarUDY4dMnTxrw8bV+plUfaL7hYaEr1iVNGP6nJkz5qxfu+XHn76bN38GlUr18em+bu3m0FDs+1hvYnxeV/IXhe986kWjd8G7NfN4cKmW50QOH2BkahfuCxa4WVjgZmGBm4UFbhYWuFlY4GZhgZuFBW4WFrhZWOBmYYGbhQVuFhbGzTq606G/wGxV0BkkCtW4EuNmtWpdQ1VHvMJsLVQUyLgOxkfPjJv1CGAI64y/svfvgUQGDu7GXz00brb3EPunNxvqK/FmCwAAV38tD+htS6UZ92bSu+JaLbJvVVHUMAeeC43NgzWMbMmoVbrGamX6X3W9Bpq6xAGKlSPu/VGbnyFl2ZFrXnVC+0UQgCC65ikKHQmVRlTItO5+NuFv27n62phQA5izgrpKoeuUNdczMjL27dvXOVuoIAiNgXoRAtRjt9ROGmp0dXeMjetHs7GaDrhlrfrflbCaJlBdXX3lypXOjgIFVmO2tLT0+PHjnR0FCqzGrJOTU1xcXGdHgQI8z8LCatosnmdhgedZWOB5FqcJq2mzeJ6FBZ5nYYHnWZwmrKbN4nkWFniehQWeZ3GasJo2i+dZWOB5FhZ4nsVpwmraLJ5nYVFRUZGSktLZUaDAaszyeLyAgIDOjgIFeJ6FhdW0WTzPwgLvz8IC78/iNGE1bRbPs7DA8yws8DyL04TVtFk8z8ICz7OwwPMsThNW02bxPAsLPM/CAs+zGJOUlHTlyhUikUggEPSbp+stX7x4sbNDM4Klt9np06e7ubnpzRIIBP17t+HhHbGAbDuxdLM9evTo0aNHy29cXFymTeuIRY/biaWbBQBMnjzZ2dm5+WN4eHhQUFCnRmQSVmA2JCQkNDRU/7NAIJgyZUpnR2QSVmC2ZbMNCwsLDAzs7HBMAvsV1GGgb7YqlcpaGiz2vS5hrTo/Q1LxUilp0MilWhtbcmM1Ngt4IAii1WrJZMyaAp1BIlMINiyygxvNM4DuGcjE6sx6MDP76Frj0xShWomw+AwGl06mkvT/MDk5DBAtolZpNEqtVq0VVUnFtXK/SHbEQK69AJuFcjAwm3lXdPd8HUfA4jiz6CxrXb8H0SHiOllNfoOTJy02kc/ktPc/R7vMqlXg993lajXRsbsdhWYdKdsoDeViWZ00rD8npI9Jaxy1hvlmVQrdgXUvBQF8Wz6jPRFYJqVPKruH2fQZbm/2Gcw0q5Bpj39X7hzoSKF3kab6JhXPawKjGOFvsc2rbmZ/dv+aYtcQQRfWCgBwDnLISZc/utFoXnVzzB7d8so9TECiWMddRnsQ+PMz74pL82QmlH0d1HbSrtSTGXSmnfn7zFkXbmHOV4/UIDrUOROdWZ0OSb1Qz/fCfj9Ii4VIJDB5zNSL9agroip96/dagZ/5l0srxcHH7vH1Ro1ah6oWCrOIDslLF/M9Oehj6yA27Zx08txGGGfme3MyUF7KUJgtfi6jc4yvaNslYfEYuY9Q7LOLzmxuhoRpj/FjC2uBwaFJhBqpSGN6FRQdUlGdhuthZIs8s9FqNRev/Jidm9LYWOntGRYTPS7I//8AABVVBVt2Tf7kw73Xbh3IzL7JYTuGhw4eMXg+iUQCAFRWFx49ubaqpqibT8SgAbMgxabH3o1ZViD362lrYnkUbbamVE6C9uzq9/Obb9870i963BeLT4cGDzx4dOnTzGsAADKJAgA4ceabnj2Gblh1Z3Limpsp/32SdQUAoNGofz64kMtxXPLJsZFDPr5x57BYXAspPACAVkOQNKBos6aaVcq1RBKRSISyAYBarUzL+GPgWzP6Rr3DZHCiI8b07DH0rxu/NBcICx4YFhJHJlN8vXvx7FxfleUAAJ49v94orBozfJEdVyBw9EkYlSRXiGGEp4dEJUmEEMxKRRquANbdQWl5tkaj8usW3fyNr1eviqp8qUyo/+jm8vcIDZ1uqzdYW1dKpdDt7ZoGH9m2fC7HCVKEAACqDVmLQqzJeZbOIImqlQI4LxEq5BIAwPc/z3nte7GkjkQkAwAIBAMtQCYXUWn/eMxGIUO8M1QrtToaijsxU80ybMkqheG9u9sPm80HACTGL+Pbu7f83o4jELWeOhk2bKXyH3f0CiW6jhEqNEqtrR2KywyKvgGdRdIotWQa9hcxB54HhUIDAHTzidB/I5bUIwhCozFA65nTjuusVisqqvKdnboBAMoqckXiGsxja0ar1jA5pi5Mj65vwHOmyURQ1vun0RhDYj/46/ovhS8z1BrV08xryfsXnDpv5G4qOLA/mUw9cfoblUohFNUcPv4lgwHx/lApVjm5o8g2KNqBRr7RAAACSUlEQVSsX0/m01Qp2wHKCELsW9NcnP2u3z6YV/CQTmd5uYeOi/+i7So2dNb7U7f+cXnXl18NpFLoI4d8/OjpJUibF6nkGp1Wx3dFcQuKYkxBJtYc/rrEr7+nueFZMXUlQns7Tex4R9OroMgGDFuys6+NuFZuVmzWjVwoD45BN2yDbrglZqT9mZ8qbflurRX48ivDk4d1Oi2B0DQH9k2WLjzJYmJ23/zLoc+KSp4YPMSwYcvkIoOH1i+/2toJhZUSLo/o6IauS4d6hPHCvkqVzobrYnjEuL6hHNXZ9NjbuZhRqzVEolqN1vC2W0qlnEYzfH1vI4a8lNIJn7my7SmowkBtVqdD9q4u7tbXA1Ut66WhtNHVixA1BPXzftTjYEQiYexcl6KHZWgrWiPCKgmZoDJDq5ljt3wX2sBxvLLMKjPqWhGiKqlOJhv9gbMJZQ1g5si2ZyDzrTHc4q7bchvKRLJaYcI8M7W2d15XzSvl79+XOfnzOU5dZ6xBo9YKy4RsDjJ4More65u0dy6iTqM7v7eqrlLt6GvPtEdxW22BIDqkuqChsVzc/x1+YJSZk46awWb+bHWp4u75htoyJZPPsHVgMDg0IslqZtCoFRpRjUxaJyOTke5hzN5DsJlNgeWcb1GduvCZNPexRFir0qoRqg3Zlk9XSNRYnR9zFBK1UqZ18mLYOZH9wlkeAVg+EoHyDiOCICqFTibSyqVaBN38h46DTCUy2SQmm0SAMwRl6W+HWi9Wkw2tDtwsLHCzsMDNwgI3CwvcLCz+HynmfAKiNy7VAAAAAElFTkSuQmCC",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "display(Image(app.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "51d13dbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t--- Starting Code Generation Task ---\n",
      "Type 'exit' to end the conversation.\n",
      "\t---GENERATOR AGENT: Thinking...\n",
      "\t---GENERATOR AGENT: Generated new code.---\n",
      "\t---EXECUTOR AGENT: Attempting to execute code.---\n",
      "\tCODE:\n",
      "--- ### ---\n",
      "def is_perfect(n):\n",
      "    sum = 0\n",
      "    for i in range(1, n):\n",
      "        if n % i == 0:\n",
      "            sum += i\n",
      "    return sum == n\n",
      "\n",
      "def find_smallest_perfect():\n",
      "    smallest = None\n",
      "    for num in range(1, 32000):\n",
      "        if is_perfect(num):\n",
      "            if smallest is None or smallest > num:\n",
      "                smallest = num\n",
      "    return smallest\n",
      "\n",
      "def prime_factors(n):\n",
      "    factors = []\n",
      "    i = 2\n",
      "    while i * i <= n:\n",
      "        if n % i == 0:\n",
      "            n //= i\n",
      "            factors.append(i)\n",
      "        else:\n",
      "            i += 1\n",
      "    if n > 1:\n",
      "        factors.append(n)\n",
      "    return factors\n",
      "\n",
      "def main():\n",
      "    number = 100\n",
      "    print(\"Prime factors of\", number, \"are:\", prime_factors(number))\n",
      "    smallest_perfect = find_smallest_perfect()\n",
      "    print(\"Smallest perfect number is:\", smallest_perfect)\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    main()\n",
      "--- ### ---\n",
      "\t---EXECUTOR AGENT: Execution successful.---\n",
      "--- ### ---\n",
      "OUTPUT:\n",
      "Prime factors of 100 are: [2, 2, 5, 5]\n",
      "Smallest perfect number is: 6\n",
      "\n",
      "--- ### ---\n",
      "---ROUTER: Analyzing execution results...---\n",
      "---ROUTER: Execution successful. Ending workflow.---\n",
      "--- ### ---\n",
      "--- Task Finished ---\n",
      "--- ### ---\n",
      "Final Code:\n",
      "--- ### ---\n",
      "def is_perfect(n):\n",
      "    sum = 0\n",
      "    for i in range(1, n):\n",
      "        if n % i == 0:\n",
      "            sum += i\n",
      "    return sum == n\n",
      "\n",
      "def find_smallest_perfect():\n",
      "    smallest = None\n",
      "    for num in range(1, 32000):\n",
      "        if is_perfect(num):\n",
      "            if smallest is None or smallest > num:\n",
      "                smallest = num\n",
      "    return smallest\n",
      "\n",
      "def prime_factors(n):\n",
      "    factors = []\n",
      "    i = 2\n",
      "    while i * i <= n:\n",
      "        if n % i == 0:\n",
      "            n //= i\n",
      "            factors.append(i)\n",
      "        else:\n",
      "            i += 1\n",
      "    if n > 1:\n",
      "        factors.append(n)\n",
      "    return factors\n",
      "\n",
      "def main():\n",
      "    number = 100\n",
      "    print(\"Prime factors of\", number, \"are:\", prime_factors(number))\n",
      "    smallest_perfect = find_smallest_perfect()\n",
      "    print(\"Smallest perfect number is:\", smallest_perfect)\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    main()\n",
      "\n",
      "--- ### ---\n",
      " Final Result:\n",
      "--- ### ---\n",
      "Execution successful. Output:\n",
      "Prime factors of 100 are: [2, 2, 5, 5]\n",
      "Smallest perfect number is: 6\n",
      "\n",
      "--- ### ---\n",
      "\t---GENERATOR AGENT: Thinking...\n",
      "\t---GENERATOR AGENT: Generated new code.---\n",
      "\t---EXECUTOR AGENT: Attempting to execute code.---\n",
      "\tCODE:\n",
      "--- ### ---\n",
      "def is_prime(n):\n",
      "    if n <= 1:\n",
      "        return False\n",
      "    for i in range(2, int(n**0.5) + 1):\n",
      "        if n % i == 0:\n",
      "            return False\n",
      "    return True\n",
      "\n",
      "def prime_factors(n):\n",
      "    factors = []\n",
      "    i = 2\n",
      "    while i * i <= n:\n",
      "        if n % i == 0:\n",
      "            n //= i\n",
      "            factors.append(i)\n",
      "        else:\n",
      "            i += 1\n",
      "    if n > 1:\n",
      "        factors.append(n)\n",
      "    return factors\n",
      "\n",
      "def main():\n",
      "    number = 100\n",
      "    print(\"Prime factors of\", number, \"are:\", *prime_factors(number))\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    main()\n",
      "--- ### ---\n",
      "\t---EXECUTOR AGENT: Execution successful.---\n",
      "--- ### ---\n",
      "OUTPUT:\n",
      "Prime factors of 100 are: 2 2 5 5\n",
      "\n",
      "--- ### ---\n",
      "---ROUTER: Analyzing execution results...---\n",
      "---ROUTER: Execution successful. Ending workflow.---\n",
      "--- ### ---\n",
      "--- Task Finished ---\n",
      "--- ### ---\n",
      "Final Code:\n",
      "--- ### ---\n",
      "def is_prime(n):\n",
      "    if n <= 1:\n",
      "        return False\n",
      "    for i in range(2, int(n**0.5) + 1):\n",
      "        if n % i == 0:\n",
      "            return False\n",
      "    return True\n",
      "\n",
      "def prime_factors(n):\n",
      "    factors = []\n",
      "    i = 2\n",
      "    while i * i <= n:\n",
      "        if n % i == 0:\n",
      "            n //= i\n",
      "            factors.append(i)\n",
      "        else:\n",
      "            i += 1\n",
      "    if n > 1:\n",
      "        factors.append(n)\n",
      "    return factors\n",
      "\n",
      "def main():\n",
      "    number = 100\n",
      "    print(\"Prime factors of\", number, \"are:\", *prime_factors(number))\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    main()\n",
      "\n",
      "--- ### ---\n",
      " Final Result:\n",
      "--- ### ---\n",
      "Execution successful. Output:\n",
      "Prime factors of 100 are: 2 2 5 5\n",
      "\n",
      "--- ### ---\n",
      "\t---GENERATOR AGENT: Thinking...\n",
      "\t---GENERATOR AGENT: Generated new code.---\n",
      "\t---EXECUTOR AGENT: Attempting to execute code.---\n",
      "\tCODE:\n",
      "--- ### ---\n",
      "def is_prime(n):\n",
      "    if n <= 1:\n",
      "        return False\n",
      "    for i in range(2, int(n**0.5) + 1):\n",
      "        if n % i == 0:\n",
      "            return False\n",
      "    return True\n",
      "\n",
      "def prime_factors(n):\n",
      "    factors = []\n",
      "    i = 2\n",
      "    while i * i <= n:\n",
      "        if n % i == 0:\n",
      "            n //= i\n",
      "            factors.append(i)\n",
      "        else:\n",
      "            i += 1\n",
      "    if n > 1:\n",
      "        factors.append(n)\n",
      "    return list(set(factors))\n",
      "\n",
      "print(*prime_factors(100))\n",
      "--- ### ---\n",
      "\t---EXECUTOR AGENT: Execution successful.---\n",
      "--- ### ---\n",
      "OUTPUT:\n",
      "2 5\n",
      "\n",
      "--- ### ---\n",
      "---ROUTER: Analyzing execution results...---\n",
      "---ROUTER: Execution successful. Ending workflow.---\n",
      "--- ### ---\n",
      "--- Task Finished ---\n",
      "--- ### ---\n",
      "Final Code:\n",
      "--- ### ---\n",
      "def is_prime(n):\n",
      "    if n <= 1:\n",
      "        return False\n",
      "    for i in range(2, int(n**0.5) + 1):\n",
      "        if n % i == 0:\n",
      "            return False\n",
      "    return True\n",
      "\n",
      "def prime_factors(n):\n",
      "    factors = []\n",
      "    i = 2\n",
      "    while i * i <= n:\n",
      "        if n % i == 0:\n",
      "            n //= i\n",
      "            factors.append(i)\n",
      "        else:\n",
      "            i += 1\n",
      "    if n > 1:\n",
      "        factors.append(n)\n",
      "    return list(set(factors))\n",
      "\n",
      "print(*prime_factors(100))\n",
      "\n",
      "--- ### ---\n",
      " Final Result:\n",
      "--- ### ---\n",
      "Execution successful. Output:\n",
      "2 5\n",
      "\n",
      "--- ### ---\n"
     ]
    }
   ],
   "source": [
    "# --- Run the agent with the sample input ---\n",
    "print(\"### Starting Code Generation Task ---\\nType 'exit' to end the conversation.\")\n",
    "while True:\n",
    "    user_input = input(\"\\nYour request: \")\n",
    "    if user_input.lower() == 'exit':\n",
    "        break\n",
    "    \n",
    "    # Load conversation history and add the new user request\n",
    "    messages = load_messages()\n",
    "    new_user_message = HumanMessage(content=user_input)\n",
    "    save_message(new_user_message) # Save the new request to memory\n",
    "    messages.append(new_user_message)\n",
    "\n",
    "    # The initial state for the graph\n",
    "    initial_state = {\n",
    "        \"task\": user_input,\n",
    "        \"messages\": messages,\n",
    "    }\n",
    "    \n",
    "    # Invoke the app. It will run until it succeeds or you interrupt it.\n",
    "    final_state = app.invoke(initial_state)\n",
    "\n",
    "    print(\"--- ### ---\")\n",
    "    print(\"--- Task Finished ---\\n--- ### ---\")\n",
    "    print(\"Final Code:\\n--- ### ---\")\n",
    "    print(final_state['code'])\n",
    "    print(\"\\n--- ### ---\\n Final Result:\\n--- ### ---\")\n",
    "    print(final_state['result'])\n",
    "    print(\"--- ### ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d609a1da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
